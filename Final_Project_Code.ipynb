{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riot - Data Dragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for 170 champions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Data Dragon URL for latest version\n",
    "VERSIONS_URL = \"https://ddragon.leagueoflegends.com/api/versions.json\"\n",
    "BASE_URL = \"https://ddragon.leagueoflegends.com/cdn\"\n",
    "\n",
    "# Get latest game version\n",
    "def get_latest_version():\n",
    "    res = requests.get(VERSIONS_URL)\n",
    "    res.raise_for_status()\n",
    "    versions = res.json()\n",
    "    return versions[0]\n",
    "\n",
    "# Load champion data\n",
    "def get_champion_data(version):\n",
    "    champ_list_url = f\"{BASE_URL}/{version}/data/en_US/champion.json\"\n",
    "    res = requests.get(champ_list_url)\n",
    "    res.raise_for_status()\n",
    "    champions = res.json()[\"data\"]\n",
    "    return champions\n",
    "\n",
    "# Get full details for each champion\n",
    "def get_detailed_champion_data(version, champ_id):\n",
    "    detail_url = f\"{BASE_URL}/{version}/data/en_US/champion/{champ_id}.json\"\n",
    "    res = requests.get(detail_url)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"data\"][champ_id]\n",
    "\n",
    "# Extract relevant text and save\n",
    "def build_champion_text_dataset():\n",
    "    version = get_latest_version()\n",
    "    champions = get_champion_data(version)\n",
    "    \n",
    "    all_champions = []\n",
    "    \n",
    "    for champ_key in champions:\n",
    "        champ_id = champions[champ_key][\"id\"]\n",
    "        detail = get_detailed_champion_data(version, champ_id)\n",
    "        \n",
    "        name = detail[\"name\"]\n",
    "        title = detail[\"title\"]\n",
    "        blurb = detail[\"blurb\"]\n",
    "        \n",
    "        passive = detail[\"passive\"][\"description\"]\n",
    "        spells = [spell[\"description\"] for spell in detail[\"spells\"]]\n",
    "        \n",
    "        full_text = f\"{name}, {title}. {blurb} Passive: {passive} \" + \" \".join([f\"Spell: {s}\" for s in spells])\n",
    "        \n",
    "        all_champions.append({\n",
    "            \"name\": name,\n",
    "            \"title\": title,\n",
    "            \"blurb\": blurb,\n",
    "            \"passive\": passive,\n",
    "            \"spells\": spells,\n",
    "            \"full_text\": full_text\n",
    "        })\n",
    "    \n",
    "    # Save as JSON\n",
    "    with open(\"riot_champion_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_champions, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Saved data for {len(all_champions)} champions.\")\n",
    "\n",
    "# Run it\n",
    "build_champion_text_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoL Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved data for 170 champions to wiki_champion_data.json.\n",
      "{\n",
      "  \"champion\": \"Ahri\",\n",
      "  \"title\": \"Ahri (Character)\",\n",
      "  \"roles\": \"Little Fox\",\n",
      "  \"abilities\": \"Since childhood, Ahri has observed human civilization from afar until she encountered a hunter dying from a stray arrow. Curiously sensing his fading life force, Ahri got her first taste of spiritual essence and absorbed the man's memories, gaining all his knowledge and experiences. Since then, Ahri hunted down human prey for years, drunkenly drinking their essence and learning to manipulate them with her charms. She slowly felt a sense of regret as she grew empathetic from absorbing human emotions, eventually seeing how they perceived her as a monstrous fox demon. Despite this, Ahri accepted her monstrous nature and continued to feast on human essence. It wasn't until she met her first and only love, a human artist, that she began to feel true sympathy for humans and decided to completely Now, after befriending  Yasuo and the rest of  Sarah Fortune's crew, she feels a deep sense of empathy and sympathy or her prey, sparing them from her hunger by learning to control it. Years ago, Ahri fell in love with a human artist who remains as her first and only true love. Unlike the rest of Ahri's prey, the artist was the first person to willingly offer his essence to Ahri in exchange for her love, to which she agreed. From there, she felt true happiness for the first time as the two would often lay in a lake at the edge of Ionia. Unfortunately, Ahri lost control of her hunger one day and accidentally drained her lover completely, thoroughly killing him. For years Ahri lived in constant regret over the death of her lover and attempted to remove the memories of him entirely at the Garden of Forgetting. In the process though, Ahri realized that her memories of her lover were too valuable to simply let go of and decided to live with them, no matter how painful it is to remember. Ahri finally found closure with the death of her lover when she cleansed the memories of her ancestors from the sunstones at the Buhru forge. In the process of this, Ahri sorrowed over the loss of the memories of her ancestors but was confronted with a memory of her lover, who urged Ahri to fight for the future and told her to live life to create new memories instead of dwelling on her old ones. This interaction defined Ahri, allowing her to live as she does now, as a protector of life in the same vein as her Vesani ancestors. Hirin was a fortune teller that Ahri encountered in an  Ionian market during her search for clues about her long-lost vastayan tribe. The fortune teller recognized Ahri's mysterious set of twin sunstones as the work of Ymelo, which intrigued Ahri as she agreed to enter her caravan for tea and to discuss more about her stones. Hirin revealed everything she knew about Ymelo to Ahri, before pulling out a hunting knife and revealing that she had put a paralysis potion in Ahri's cup of tea. Wishing to cut off one of her tails as an ingredient for her potions, Ahri managed to absorb enough of Hirin's essence to regain her strength and defend herself. Though she was furious at the betrayal, she looked into Hirin's memories and hardships in life, deciding to spare her life and leaving her without any memory of their encounter, essentially making her forget Ahri completely.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "def scrape_lol_wiki(champion_name):\n",
    "    url_name = champion_name.replace(\" \", \"_\")\n",
    "    url = f\"https://leagueoflegends.fandom.com/wiki/{url_name}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {champion_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Get title from page header\n",
    "    title_el = soup.find(\"h1\", {\"class\": \"page-header__title\"})\n",
    "    title = title_el.text.strip() if title_el else \"\"\n",
    "\n",
    "    # Find roles\n",
    "    role_box = soup.find(\"div\", {\"class\": \"pi-data-value pi-font\"})\n",
    "    roles = role_box.text.strip() if role_box else \"\"\n",
    "\n",
    "    # Ability descriptions (grab first few paragraphs under abilities section)\n",
    "    ability_section = soup.find(\"span\", {\"id\": \"Abilities\"})\n",
    "    if ability_section:\n",
    "        ability_texts = []\n",
    "        for tag in ability_section.find_parent().find_next_siblings(\"p\", limit=6):\n",
    "            ability_texts.append(tag.get_text().strip())\n",
    "        abilities = \" \".join(ability_texts)\n",
    "    else:\n",
    "        abilities = \"\"\n",
    "\n",
    "    return {\n",
    "        \"champion\": champion_name,\n",
    "        \"title\": title,\n",
    "        \"roles\": roles,\n",
    "        \"abilities\": abilities\n",
    "    }\n",
    "\n",
    "def save_all_wiki_data_from_riot_json(riot_filename=\"riot_champion_data.json\"):\n",
    "    # Load all champion names from Riot JSON\n",
    "    try:\n",
    "        with open(riot_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            riot_data = json.load(f)\n",
    "        champion_names = [entry[\"name\"] for entry in riot_data]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {riot_filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "    for i, name in enumerate(champion_names):\n",
    "        #print(f\"Scraping {name} ({i+1}/{len(champion_names)})...\")         #uncomment to verify progress\n",
    "        data = scrape_lol_wiki(name)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "            #print(\"Sample entry:\", data)       #uncomment to verify progress\n",
    "        time.sleep(1.5)  # Prevent overloading the site\n",
    "\n",
    "    with open(\"wiki_champion_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\nSaved data for {len(all_data)} champions to wiki_champion_data.json.\")\n",
    "\n",
    "# Run it\n",
    "save_all_wiki_data_from_riot_json()\n",
    "\n",
    "# Printing Ahri's data as an example\n",
    "with open(\"wiki_champion_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki_data = json.load(f)\n",
    "    for champion in wiki_data:\n",
    "        if champion[\"champion\"] == \"Ahri\":\n",
    "            print(json.dumps(champion, indent=2, ensure_ascii=False))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobafire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved data for 170 champions to mobafire_champion_data.json.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Known problematic Mobafire champion URL fixes\n",
    "MOBALFIRE_NAME_FIXES = {\n",
    "    \"Aurelion Sol\": \"aurelion-sol-130\",\n",
    "    \"Bel'Veth\": \"belveth\",\n",
    "    \"Cho'Gath\": \"chogath\",\n",
    "    \"Dr. Mundo\": \"dr-mundo-26\",\n",
    "    \"Jarvan IV\": \"jarvan-iv-71\",\n",
    "    \"Kai'Sa\": \"kaisa\",\n",
    "    \"Kha'Zix\": \"khazix\",\n",
    "    \"Kog'Maw\": \"kogmaw\",\n",
    "    \"K'Sante\": \"ksante\",\n",
    "    \"Lee Sin\": \"lee-sin-73\",\n",
    "    \"Master Yi\": \"master-yi-3\",\n",
    "    \"Miss Fortune\": \"miss-fortune-59\",\n",
    "    \"Nunu & Willump\": \"nunu-amp-willump-12\",\n",
    "    \"Rek'Sai\": \"reksai\",\n",
    "    \"Renata Glasc\": \"renata-glasc-175\",\n",
    "    \"Tahm Kench\": \"tahm-kench-126\",\n",
    "    \"Twisted Fate\": \"twisted-fate-28\",\n",
    "    \"Vel'Koz\": \"velkoz\",\n",
    "    \"Xin Zhao\": \"xin-zhao-55\",\n",
    "    \"Wukong\": \"wukong-80\",\n",
    "}\n",
    "\n",
    "# Format fallback names and fix special characters\n",
    "def format_mobafire_name(name):\n",
    "    if name in MOBALFIRE_NAME_FIXES:\n",
    "        return MOBALFIRE_NAME_FIXES[name]\n",
    "\n",
    "    fallback = name.lower().replace(\" \", \"-\")\n",
    "    fallback = fallback.replace(\"'\", \"\").replace(\".\", \"\").replace(\"&\", \"and\")\n",
    "    fallback = re.sub(r\"[^\\w\\-]\", \"\", fallback)\n",
    "    return fallback\n",
    "\n",
    "# Scrape a single champion's Mobafire guide description\n",
    "def scrape_mobafire_description(champion_name):\n",
    "    base_name = format_mobafire_name(champion_name)\n",
    "    listing_url = f\"https://www.mobafire.com/league-of-legends/champion/{base_name}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    try:\n",
    "        listing_response = requests.get(listing_url, headers=headers)\n",
    "        listing_response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {champion_name} listing page: {e}\")\n",
    "        return {\"champion\": champion_name, \"mobafire_description\": \"Error loading page\"}\n",
    "\n",
    "    listing_soup = BeautifulSoup(listing_response.text, \"html.parser\")\n",
    "\n",
    "    guide_link_tag = listing_soup.find(\"a\", class_=\"browse-list__guide-title\")\n",
    "    if not guide_link_tag or \"href\" not in guide_link_tag.attrs:\n",
    "        return {\"champion\": champion_name, \"mobafire_description\": \"No guide found\"}\n",
    "\n",
    "    guide_url = \"https://www.mobafire.com\" + guide_link_tag[\"href\"]\n",
    "\n",
    "    try:\n",
    "        guide_response = requests.get(guide_url, headers=headers)\n",
    "        guide_response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch guide for {champion_name}: {e}\")\n",
    "        return {\"champion\": champion_name, \"mobafire_description\": \"Error loading guide\"}\n",
    "\n",
    "    guide_soup = BeautifulSoup(guide_response.text, \"html.parser\")\n",
    "\n",
    "    content_div = guide_soup.find(\"div\", class_=\"view-guide__full\")\n",
    "    if not content_div:\n",
    "        return {\"champion\": champion_name, \"mobafire_description\": \"No content found\"}\n",
    "\n",
    "    text = content_div.get_text(separator=\" \", strip=True)\n",
    "    return {\n",
    "        \"champion\": champion_name,\n",
    "        \"mobafire_description\": text[:1000]  # Limit to first 1000 chars\n",
    "    }\n",
    "\n",
    "# Load champion names and run the full scrape\n",
    "def save_all_mobafire_data_from_riot_json(riot_filename=\"riot_champion_data.json\"):\n",
    "    try:\n",
    "        with open(riot_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            riot_data = json.load(f)\n",
    "        champion_names = [entry[\"name\"] for entry in riot_data]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {riot_filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "    for i, name in enumerate(champion_names):\n",
    "        #print(f\"Scraping Mobafire guide for {name} ({i+1}/{len(champion_names)})...\")\n",
    "        data = scrape_mobafire_description(name)\n",
    "        all_data.append(data)\n",
    "        time.sleep(2)  # Be kind to Mobafire servers\n",
    "\n",
    "    with open(\"mobafire_champion_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nSaved data for {len(all_data)} champions to mobafire_champion_data.json.\")\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == '__main__':\n",
    "    save_all_mobafire_data_from_riot_json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 3 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 170 champions to compiled_champion_profiles.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load all sources\n",
    "riot_data = load_json(\"riot_champion_data.json\")\n",
    "wiki_data = load_json(\"wiki_champion_data.json\")\n",
    "mobafire_data = load_json(\"mobafire_champion_data.json\")\n",
    "\n",
    "# Convert wiki and mobafire to dicts for faster lookup\n",
    "wiki_lookup = {entry[\"champion\"]: entry for entry in wiki_data}\n",
    "mobafire_lookup = {entry[\"champion\"]: entry for entry in mobafire_data}\n",
    "\n",
    "# Merge data\n",
    "compiled = []\n",
    "\n",
    "for entry in riot_data:\n",
    "    name = entry[\"name\"]\n",
    "    riot_text = entry.get(\"full_text\", \"\")\n",
    "    wiki_text = wiki_lookup.get(name, {}).get(\"abilities\", \"\")\n",
    "    mobafire_text = mobafire_lookup.get(name, {}).get(\"mobafire_description\", \"\")\n",
    "\n",
    "    combined_text = f\"{riot_text}\\n\\nWIKI:\\n{wiki_text}\\n\\nMOBAFIRE:\\n{mobafire_text}\"\n",
    "\n",
    "    compiled.append({\n",
    "        \"champion\": name,\n",
    "        \"combined_text\": combined_text\n",
    "    })\n",
    "\n",
    "# Save the final compiled profile\n",
    "with open(\"compiled_champion_profiles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(compiled, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(compiled)} champions to compiled_champion_profiles.json.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
